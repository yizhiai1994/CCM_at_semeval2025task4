{"forget-set": {"overall-regurgitation-score": 0.615740130023305, "overall-knowledge-score": 0.791907514450867, "Task1": {"regurgitation-score": 0.7070650803625381, "knowledge-score": 0.9166666666666666}, "Task2": {"regurgitation-score": 0.754760369685172, "knowledge-score": 0.7565217391304347}, "Task3": {"regurgitation-score": 0.457232355894936, "knowledge-score": 0.8235294117647058}}, "retain-set": {"overall-regurgitation-score": 0.6202362707100209, "overall-knowledge-score": 0.8359788359788359, "Task1": {"regurgitation-score": 0.8382926855604201, "knowledge-score": 0.9629629629629629}, "Task2": {"regurgitation-score": 0.6812452506613289, "knowledge-score": 0.808}, "Task3": {"regurgitation-score": 0.4198917382845218, "knowledge-score": 0.8378378378378378}}, "mia_loss_acc": 0.99752, "mmlu_average": 0.2746759720837488, "aggregated-terms": [0.2929349196374619, 0.08333333333333337, 0.24523963031482798, 0.24347826086956526, 0.542767644105064, 0.17647058823529416, 0.8382926855604201, 0.9629629629629629, 0.6812452506613289, 0.808, 0.4198917382845218, 0.8378378378378378], "aggregate-score": 0.19417214363998916, "harmonic-mean-task-aggregate": 0.30288045883621867, "mia_final_score": 0.0049600000000000755}