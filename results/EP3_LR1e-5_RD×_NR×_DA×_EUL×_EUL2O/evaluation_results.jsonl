{"forget-set": {"overall-regurgitation-score": 0.958199931933747, "overall-knowledge-score": 1.0, "Task1": {"regurgitation-score": 0.9811507936507936, "knowledge-score": 1.0}, "Task2": {"regurgitation-score": 0.9212402895011591, "knowledge-score": 1.0}, "Task3": {"regurgitation-score": 0.9670014347202295, "knowledge-score": 1.0}}, "retain-set": {"overall-regurgitation-score": 0.9716818724891366, "overall-knowledge-score": 1.0, "Task1": {"regurgitation-score": 0.97578223384675, "knowledge-score": 1.0}, "Task2": {"regurgitation-score": 0.925342653506836, "knowledge-score": 1.0}, "Task3": {"regurgitation-score": 1.0, "knowledge-score": 1.0}}, "mia_loss_acc": 1.0, "mmlu_average": 0.27795185870958555, "aggregated-terms": [0.018849206349206393, 0.0, 0.0787597104988409, 0.0, 0.03299856527977052, 0.0, 0.97578223384675, 1.0, 0.925342653506836, 1.0, 1.0, 1.0], "aggregate-score": 0.09265061956986186, "harmonic-mean-task-aggregate": 0, "mia_final_score": 0.0}