{"forget-set": {"overall-regurgitation-score": 0.7181893656396322, "overall-knowledge-score": 1.0, "Task1": {"regurgitation-score": 0.7552806905781734, "knowledge-score": 1.0}, "Task2": {"regurgitation-score": 0.8362377043946042, "knowledge-score": 1.0}, "Task3": {"regurgitation-score": 0.6121510247605337, "knowledge-score": 1.0}}, "retain-set": {"overall-regurgitation-score": 0.6586062193097947, "overall-knowledge-score": 1.0, "Task1": {"regurgitation-score": 0.7682938909816511, "knowledge-score": 1.0}, "Task2": {"regurgitation-score": 0.7614587485649829, "knowledge-score": 1.0}, "Task3": {"regurgitation-score": 0.5090689121065565, "knowledge-score": 1.0}}, "mia_loss_acc": 1.0, "mmlu_average": 0.27496083179034325, "aggregated-terms": [0.24471930942182663, 0.0, 0.1637622956053958, 0.0, 0.38784897523946626, 0.0, 0.7682938909816511, 1.0, 0.7614587485649829, 1.0, 0.5090689121065565, 1.0], "aggregate-score": 0.09165361059678108, "harmonic-mean-task-aggregate": 0, "mia_final_score": 0.0}