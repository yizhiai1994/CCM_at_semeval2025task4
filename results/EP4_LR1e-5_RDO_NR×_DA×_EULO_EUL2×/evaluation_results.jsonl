{"forget-set": {"overall-regurgitation-score": 0.9304142150175954, "overall-knowledge-score": 1.0, "Task1": {"regurgitation-score": 0.9580572808833678, "knowledge-score": 1.0}, "Task2": {"regurgitation-score": 0.9152171066348759, "knowledge-score": 1.0}, "Task3": {"regurgitation-score": 0.9211818594888896, "knowledge-score": 1.0}}, "retain-set": {"overall-regurgitation-score": 0.9129147318289852, "overall-knowledge-score": 1.0, "Task1": {"regurgitation-score": 0.955986395344771, "knowledge-score": 1.0}, "Task2": {"regurgitation-score": 0.8938499041313956, "knowledge-score": 1.0}, "Task3": {"regurgitation-score": 0.8943656987888101, "knowledge-score": 1.0}}, "mia_loss_acc": 1.0, "mmlu_average": 0.27994587665574705, "aggregated-terms": [0.041942719116632166, 0.0, 0.08478289336512412, 0.0, 0.07881814051111036, 0.0, 0.955986395344771, 1.0, 0.8938499041313956, 1.0, 0.8943656987888101, 1.0], "aggregate-score": 0.09331529221858235, "harmonic-mean-task-aggregate": 0, "mia_final_score": 0.0}