{"forget-set": {"overall-regurgitation-score": 0.055446412019292936, "overall-knowledge-score": 0.0, "Task1": {"regurgitation-score": 0.055891823972780696, "knowledge-score": 0.0}, "Task2": {"regurgitation-score": 0.04558950557759976, "knowledge-score": 0.0}, "Task3": {"regurgitation-score": 0.06179991088032938, "knowledge-score": 0.0}}, "retain-set": {"overall-regurgitation-score": 0.0482443838127499, "overall-knowledge-score": 0.0, "Task1": {"regurgitation-score": 0.06256478096755329, "knowledge-score": 0.0}, "Task2": {"regurgitation-score": 0.037427009609536085, "knowledge-score": 0.0}, "Task3": {"regurgitation-score": 0.04510340089114598, "knowledge-score": 0.0}}, "mia_loss_acc": 0.529968, "mmlu_average": 0.2460475715710013, "aggregated-terms": [0.9441081760272193, 1.0, 0.9544104944224002, 1.0, 0.9382000891196707, 1.0, 0.06256478096755329, 0.0, 0.037427009609536085, 0.0, 0.04510340089114598, 0.0], "aggregate-score": 0.39537052385700044, "harmonic-mean-task-aggregate": 0, "mia_final_score": 0.940064}