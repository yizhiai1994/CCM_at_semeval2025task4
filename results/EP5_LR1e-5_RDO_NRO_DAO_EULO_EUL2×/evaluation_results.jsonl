{"forget-set": {"overall-regurgitation-score": 0.5905836363750068, "overall-knowledge-score": 0.9710982658959537, "Task1": {"regurgitation-score": 0.6493682193672473, "knowledge-score": 1.0}, "Task2": {"regurgitation-score": 0.6853414187157097, "knowledge-score": 0.9652173913043478}, "Task3": {"regurgitation-score": 0.4849877838558913, "knowledge-score": 0.9705882352941176}}, "retain-set": {"overall-regurgitation-score": 0.5393247768125695, "overall-knowledge-score": 0.9788359788359788, "Task1": {"regurgitation-score": 0.6815216518537777, "knowledge-score": 1.0}, "Task2": {"regurgitation-score": 0.6446378799414347, "knowledge-score": 0.984}, "Task3": {"regurgitation-score": 0.36440198750623853, "knowledge-score": 0.9459459459459459}}, "mia_loss_acc": 0.999792, "mmlu_average": 0.27496083179034325, "aggregated-terms": [0.3506317806327527, 0.0, 0.31465858128429025, 0.034782608695652195, 0.5150122161441086, 0.02941176470588236, 0.6815216518537777, 1.0, 0.6446378799414347, 0.984, 0.36440198750623853, 0.9459459459459459], "aggregate-score": 0.09179227726344774, "harmonic-mean-task-aggregate": 0, "mia_final_score": 0.00041599999999997195}