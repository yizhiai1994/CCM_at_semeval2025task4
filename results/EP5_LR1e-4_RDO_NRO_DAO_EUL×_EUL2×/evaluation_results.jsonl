{"forget-set": {"overall-regurgitation-score": 0.9384717847680811, "overall-knowledge-score": 0.4624277456647399, "Task1": {"regurgitation-score": 0.9670634920634921, "knowledge-score": 0.5416666666666666}, "Task2": {"regurgitation-score": 0.8579365079365079, "knowledge-score": 0.43478260869565216}, "Task3": {"regurgitation-score": 0.9727691492397375, "knowledge-score": 0.5}}, "retain-set": {"overall-regurgitation-score": 0.9559384644885545, "overall-knowledge-score": 0.4497354497354497, "Task1": {"regurgitation-score": 0.9762455908289241, "knowledge-score": 0.5555555555555556}, "Task2": {"regurgitation-score": 0.8907004573887777, "knowledge-score": 0.456}, "Task3": {"regurgitation-score": 0.9851994851994851, "knowledge-score": 0.35135135135135137}}, "mia_loss_acc": 1.0, "mmlu_average": 0.27809428856288276, "aggregated-terms": [0.03293650793650793, 0.45833333333333337, 0.14206349206349211, 0.5652173913043479, 0.027230850760262548, 0.5, 0.9762455908289241, 0.5555555555555556, 0.8907004573887777, 0.456, 0.9851994851994851, 0.35135135135135137], "aggregate-score": 0.1371051113194282, "harmonic-mean-task-aggregate": 0.1332210453954019, "mia_final_score": 0.0}