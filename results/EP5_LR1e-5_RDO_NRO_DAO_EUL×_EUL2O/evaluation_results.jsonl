{"forget-set": {"overall-regurgitation-score": 0.7246856409376505, "overall-knowledge-score": 1.0, "Task1": {"regurgitation-score": 0.7486511538448974, "knowledge-score": 1.0}, "Task2": {"regurgitation-score": 0.8773432413697064, "knowledge-score": 1.0}, "Task3": {"regurgitation-score": 0.6045004315343796, "knowledge-score": 1.0}}, "retain-set": {"overall-regurgitation-score": 0.6362570296814283, "overall-knowledge-score": 0.9947089947089947, "Task1": {"regurgitation-score": 0.7766967912364031, "knowledge-score": 1.0}, "Task2": {"regurgitation-score": 0.8046005503136808, "knowledge-score": 1.0}, "Task3": {"regurgitation-score": 0.42002833838978965, "knowledge-score": 0.972972972972973}}, "mia_loss_acc": 0.999984, "mmlu_average": 0.27496083179034325, "aggregated-terms": [0.25134884615510256, 0.0, 0.12265675863029357, 0.0, 0.3954995684656204, 0.0, 0.7766967912364031, 1.0, 0.8046005503136808, 1.0, 0.42002833838978965, 0.972972972972973], "aggregate-score": 0.09166427726344777, "harmonic-mean-task-aggregate": 0, "mia_final_score": 3.2000000000032e-05}