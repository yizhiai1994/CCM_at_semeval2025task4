{"forget-set": {"overall-regurgitation-score": 0.8279627372573527, "overall-knowledge-score": 0.005780346820809248, "Task1": {"regurgitation-score": 0.8531400078570547, "knowledge-score": 0.041666666666666664}, "Task2": {"regurgitation-score": 0.6672982081527618, "knowledge-score": 0.0}, "Task3": {"regurgitation-score": 0.9188753747577277, "knowledge-score": 0.0}}, "retain-set": {"overall-regurgitation-score": 0.8372591170656235, "overall-knowledge-score": 0.010582010582010581, "Task1": {"regurgitation-score": 0.8782763476909236, "knowledge-score": 0.07407407407407407}, "Task2": {"regurgitation-score": 0.6611093178842854, "knowledge-score": 0.0}, "Task3": {"regurgitation-score": 0.9263477590291463, "knowledge-score": 0.0}}, "mia_loss_acc": 1.0, "mmlu_average": 0.2783791482694773, "aggregated-terms": [0.14685999214294532, 0.9583333333333334, 0.33270179184723825, 1.0, 0.08112462524227226, 1.0, 0.8782763476909236, 0.07407407407407407, 0.6611093178842854, 0.0, 0.9263477590291463, 0.0], "aggregate-score": 0.0927930494231591, "harmonic-mean-task-aggregate": 0, "mia_final_score": 0.0}