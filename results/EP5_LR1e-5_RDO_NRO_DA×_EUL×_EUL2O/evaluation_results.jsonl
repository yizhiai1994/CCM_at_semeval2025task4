{"forget-set": {"overall-regurgitation-score": 0.6506765765326669, "overall-knowledge-score": 1.0, "Task1": {"regurgitation-score": 0.5429497520193537, "knowledge-score": 1.0}, "Task2": {"regurgitation-score": 0.7768683962419702, "knowledge-score": 1.0}, "Task3": {"regurgitation-score": 0.6413539863857715, "knowledge-score": 1.0}}, "retain-set": {"overall-regurgitation-score": 0.5674916752049032, "overall-knowledge-score": 0.9894179894179894, "Task1": {"regurgitation-score": 0.5385729872523588, "knowledge-score": 1.0}, "Task2": {"regurgitation-score": 0.6480608055812971, "knowledge-score": 0.992}, "Task3": {"regurgitation-score": 0.5341558999429804, "knowledge-score": 0.972972972972973}}, "mia_loss_acc": 1.0, "mmlu_average": 0.27517447657028915, "aggregated-terms": [0.4570502479806463, 0.0, 0.22313160375802976, 0.0, 0.35864601361422854, 0.0, 0.5385729872523588, 1.0, 0.6480608055812971, 0.992, 0.5341558999429804, 0.972972972972973], "aggregate-score": 0.09172482552342971, "harmonic-mean-task-aggregate": 0, "mia_final_score": 0.0}