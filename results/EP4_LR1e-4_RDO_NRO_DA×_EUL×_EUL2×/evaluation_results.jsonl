{"forget-set": {"overall-regurgitation-score": 0.9261776331757545, "overall-knowledge-score": 0.3988439306358382, "Task1": {"regurgitation-score": 0.9271642080745343, "knowledge-score": 0.625}, "Task2": {"regurgitation-score": 0.8346529879138573, "knowledge-score": 0.34782608695652173}, "Task3": {"regurgitation-score": 0.9873949579831932, "knowledge-score": 0.4117647058823529}}, "retain-set": {"overall-regurgitation-score": 0.9521533697192605, "overall-knowledge-score": 0.37037037037037035, "Task1": {"regurgitation-score": 0.9553978797638217, "knowledge-score": 0.5185185185185185}, "Task2": {"regurgitation-score": 0.9022807305000853, "knowledge-score": 0.352}, "Task3": {"regurgitation-score": 0.9834834834834834, "knowledge-score": 0.32432432432432434}}, "mia_loss_acc": 1.0, "mmlu_average": 0.28080045577553053, "aggregated-terms": [0.07283579192546574, 0.375, 0.16534701208614266, 0.6521739130434783, 0.012605042016806789, 0.5882352941176471, 0.9553978797638217, 0.5185185185185185, 0.9022807305000853, 0.352, 0.9834834834834834, 0.32432432432432434], "aggregate-score": 0.12807241186515292, "harmonic-mean-task-aggregate": 0.10341677981992821, "mia_final_score": 0.0}