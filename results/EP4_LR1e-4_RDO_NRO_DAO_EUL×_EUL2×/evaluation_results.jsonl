{"forget-set": {"overall-regurgitation-score": 0.9285470675503892, "overall-knowledge-score": 0.5838150289017341, "Task1": {"regurgitation-score": 0.9834725422427035, "knowledge-score": 0.7083333333333334}, "Task2": {"regurgitation-score": 0.8136899687411195, "knowledge-score": 0.5739130434782609}, "Task3": {"regurgitation-score": 0.9674735934326728, "knowledge-score": 0.5294117647058824}}, "retain-set": {"overall-regurgitation-score": 0.9409010075226958, "overall-knowledge-score": 0.5238095238095238, "Task1": {"regurgitation-score": 0.9193923360590027, "knowledge-score": 0.5925925925925926}, "Task2": {"regurgitation-score": 0.901383997504576, "knowledge-score": 0.544}, "Task3": {"regurgitation-score": 0.9832972069814174, "knowledge-score": 0.40540540540540543}}, "mia_loss_acc": 1.0, "mmlu_average": 0.27496083179034325, "aggregated-terms": [0.01652745775729647, 0.29166666666666663, 0.18631003125888046, 0.4260869565217391, 0.03252640656732719, 0.47058823529411764, 0.9193923360590027, 0.5925925925925926, 0.901383997504576, 0.544, 0.9832972069814174, 0.40540540540540543], "aggregate-score": 0.12682648520800663, "harmonic-mean-task-aggregate": 0.10551862383367662, "mia_final_score": 0.0}