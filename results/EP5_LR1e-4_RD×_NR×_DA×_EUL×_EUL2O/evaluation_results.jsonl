{"forget-set": {"overall-regurgitation-score": 0.04666135238750663, "overall-knowledge-score": 0.0, "Task1": {"regurgitation-score": 0.05415571286166959, "knowledge-score": 0.0}, "Task2": {"regurgitation-score": 0.01646241151203344, "knowledge-score": 0.0}, "Task3": {"regurgitation-score": 0.06179991088032938, "knowledge-score": 0.0}}, "retain-set": {"overall-regurgitation-score": 0.04083537794826877, "overall-knowledge-score": 0.0, "Task1": {"regurgitation-score": 0.06119303885507043, "knowledge-score": 0.0}, "Task2": {"regurgitation-score": 0.012532430213464696, "knowledge-score": 0.0}, "Task3": {"regurgitation-score": 0.04510340089114598, "knowledge-score": 0.0}}, "mia_loss_acc": 0.526368, "mmlu_average": 0.23985187295257085, "aggregated-terms": [0.9458442871383304, 1.0, 0.9835375884879666, 1.0, 0.9382000891196707, 1.0, 0.06119303885507043, 0.0, 0.012532430213464696, 0.0, 0.04510340089114598, 0.0], "aggregate-score": 0.3957052909841903, "harmonic-mean-task-aggregate": 0, "mia_final_score": 0.9472640000000001}