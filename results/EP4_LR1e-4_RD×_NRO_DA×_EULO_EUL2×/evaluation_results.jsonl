{"forget-set": {"overall-regurgitation-score": 0.7675970407051311, "overall-knowledge-score": 0.005780346820809248, "Task1": {"regurgitation-score": 0.9279761904761905, "knowledge-score": 0.041666666666666664}, "Task2": {"regurgitation-score": 0.28016833328813046, "knowledge-score": 0.0}, "Task3": {"regurgitation-score": 0.9841194135311782, "knowledge-score": 0.0}}, "retain-set": {"overall-regurgitation-score": 0.7428451789760392, "overall-knowledge-score": 0.005291005291005291, "Task1": {"regurgitation-score": 0.9135917353939794, "knowledge-score": 0.037037037037037035}, "Task2": {"regurgitation-score": 0.26942234357436273, "knowledge-score": 0.0}, "Task3": {"regurgitation-score": 0.9381266346992153, "knowledge-score": 0.0}}, "mia_loss_acc": 0.9761439999999999, "mmlu_average": 0.2720410197977496, "aggregated-terms": [0.07202380952380949, 0.9583333333333334, 0.7198316667118696, 1.0, 0.015880586468821845, 1.0, 0.9135917353939794, 0.037037037037037035, 0.26942234357436273, 0.0, 0.9381266346992153, 0.0], "aggregate-score": 0.10658433993258326, "harmonic-mean-task-aggregate": 0, "mia_final_score": 0.0477120000000002}