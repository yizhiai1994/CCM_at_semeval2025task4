{"forget-set": {"overall-regurgitation-score": 0.9791692520087582, "overall-knowledge-score": 1.0, "Task1": {"regurgitation-score": 0.9970238095238094, "knowledge-score": 1.0}, "Task2": {"regurgitation-score": 0.9673479499566456, "knowledge-score": 1.0}, "Task3": {"regurgitation-score": 0.9745627980922099, "knowledge-score": 1.0}}, "retain-set": {"overall-regurgitation-score": 0.9715678864858169, "overall-knowledge-score": 1.0, "Task1": {"regurgitation-score": 0.976976976976977, "knowledge-score": 1.0}, "Task2": {"regurgitation-score": 0.9300067658950862, "knowledge-score": 1.0}, "Task3": {"regurgitation-score": 0.9957025505805993, "knowledge-score": 1.0}}, "mia_loss_acc": 1.0, "mmlu_average": 0.27496083179034325, "aggregated-terms": [0.0029761904761905766, 0.0, 0.032652050043354364, 0.0, 0.025437201907790086, 0.0, 0.976976976976977, 1.0, 0.9300067658950862, 1.0, 0.9957025505805993, 1.0], "aggregate-score": 0.09165361059678108, "harmonic-mean-task-aggregate": 0, "mia_final_score": 0.0}