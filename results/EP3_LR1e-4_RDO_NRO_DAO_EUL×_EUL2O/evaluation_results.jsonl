{"forget-set": {"overall-regurgitation-score": 0.4611670646988474, "overall-knowledge-score": 0.5664739884393064, "Task1": {"regurgitation-score": 0.6145708613504759, "knowledge-score": 1.0}, "Task2": {"regurgitation-score": 0.32700708917967936, "knowledge-score": 0.3565217391304348}, "Task3": {"regurgitation-score": 0.44363730932536966, "knowledge-score": 0.9705882352941176}}, "retain-set": {"overall-regurgitation-score": 0.4387969617380501, "overall-knowledge-score": 0.5555555555555556, "Task1": {"regurgitation-score": 0.7163650071454994, "knowledge-score": 0.9629629629629629}, "Task2": {"regurgitation-score": 0.2700149454005913, "knowledge-score": 0.376}, "Task3": {"regurgitation-score": 0.3502892099119784, "knowledge-score": 0.8648648648648649}}, "mia_loss_acc": 0.9930720000000001, "mmlu_average": 0.2723258795043441, "aggregated-terms": [0.3854291386495241, 0.0, 0.6729929108203206, 0.6434782608695653, 0.5563626906746304, 0.02941176470588236, 0.7163650071454994, 0.9629629629629629, 0.2700149454005913, 0.376, 0.3502892099119784, 0.8648648648648649], "aggregate-score": 0.09539395983478133, "harmonic-mean-task-aggregate": 0, "mia_final_score": 0.013855999999999868}