{"forget-set": {"overall-regurgitation-score": 0.6394741989863608, "overall-knowledge-score": 0.9364161849710982, "Task1": {"regurgitation-score": 0.7918264052533287, "knowledge-score": 0.9583333333333334}, "Task2": {"regurgitation-score": 0.7257095248354638, "knowledge-score": 0.9478260869565217}, "Task3": {"regurgitation-score": 0.47359580354704933, "knowledge-score": 0.8823529411764706}}, "retain-set": {"overall-regurgitation-score": 0.6192679650351264, "overall-knowledge-score": 0.9153439153439153, "Task1": {"regurgitation-score": 0.7883638514518903, "knowledge-score": 0.9259259259259259}, "Task2": {"regurgitation-score": 0.6806795277978404, "knowledge-score": 0.912}, "Task3": {"regurgitation-score": 0.4543793703778161, "knowledge-score": 0.918918918918919}}, "mia_loss_acc": 0.999584, "mmlu_average": 0.27054550633812846, "aggregated-terms": [0.2081735947466713, 0.04166666666666663, 0.2742904751645362, 0.05217391304347829, 0.5264041964529507, 0.11764705882352944, 0.7883638514518903, 0.9259259259259259, 0.6806795277978404, 0.912, 0.4543793703778161, 0.918918918918919], "aggregate-score": 0.14742388791817584, "harmonic-mean-task-aggregate": 0.1708941574163991, "mia_final_score": 0.0008319999999999439}