{"forget-set": {"overall-regurgitation-score": 0.9295854664481423, "overall-knowledge-score": 0.791907514450867, "Task1": {"regurgitation-score": 0.9175099206349207, "knowledge-score": 0.8333333333333334}, "Task2": {"regurgitation-score": 0.8946138804834457, "knowledge-score": 0.7652173913043478}, "Task3": {"regurgitation-score": 0.9617666304688877, "knowledge-score": 0.8529411764705882}}, "retain-set": {"overall-regurgitation-score": 0.9129700996508645, "overall-knowledge-score": 0.8095238095238095, "Task1": {"regurgitation-score": 0.917655989322656, "knowledge-score": 0.8518518518518519}, "Task2": {"regurgitation-score": 0.854126394969438, "knowledge-score": 0.832}, "Task3": {"regurgitation-score": 0.9493099265670076, "knowledge-score": 0.7027027027027027}}, "mia_loss_acc": 1.0, "mmlu_average": 0.27496083179034325, "aggregated-terms": [0.08249007936507935, 0.16666666666666663, 0.1053861195165543, 0.23478260869565215, 0.03823336953111234, 0.1470588235294118, 0.917655989322656, 0.8518518518518519, 0.854126394969438, 0.832, 0.9493099265670076, 0.7027027027027027], "aggregate-score": 0.14725639981718455, "harmonic-mean-task-aggregate": 0.1668083676612104, "mia_final_score": 0.0}