{"forget-set": {"overall-regurgitation-score": 0.9609300002193708, "overall-knowledge-score": 1.0, "Task1": {"regurgitation-score": 0.9761904761904763, "knowledge-score": 1.0}, "Task2": {"regurgitation-score": 0.9244366583497018, "knowledge-score": 1.0}, "Task3": {"regurgitation-score": 0.9748445719751314, "knowledge-score": 1.0}}, "retain-set": {"overall-regurgitation-score": 0.9790168394602785, "overall-knowledge-score": 1.0, "Task1": {"regurgitation-score": 0.976976976976977, "knowledge-score": 1.0}, "Task2": {"regurgitation-score": 0.9501648133434563, "knowledge-score": 1.0}, "Task3": {"regurgitation-score": 1.0, "knowledge-score": 1.0}}, "mia_loss_acc": 1.0, "mmlu_average": 0.28051559606893606, "aggregated-terms": [0.023809523809523725, 0.0, 0.07556334165029821, 0.0, 0.025155428024868587, 0.0, 0.976976976976977, 1.0, 0.9501648133434563, 1.0, 1.0, 1.0], "aggregate-score": 0.09350519868964535, "harmonic-mean-task-aggregate": 0, "mia_final_score": 0.0}