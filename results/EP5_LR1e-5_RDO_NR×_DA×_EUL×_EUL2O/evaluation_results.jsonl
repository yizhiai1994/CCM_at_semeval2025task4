{"forget-set": {"overall-regurgitation-score": 0.7223419608233579, "overall-knowledge-score": 0.976878612716763, "Task1": {"regurgitation-score": 0.7760049390269642, "knowledge-score": 0.9166666666666666}, "Task2": {"regurgitation-score": 0.8411182586229845, "knowledge-score": 0.991304347826087}, "Task3": {"regurgitation-score": 0.6041135394622412, "knowledge-score": 0.9705882352941176}}, "retain-set": {"overall-regurgitation-score": 0.7341878944098345, "overall-knowledge-score": 0.9841269841269841, "Task1": {"regurgitation-score": 0.8596933064377682, "knowledge-score": 0.9259259259259259}, "Task2": {"regurgitation-score": 0.862377191025583, "knowledge-score": 0.992}, "Task3": {"regurgitation-score": 0.5559884744058362, "knowledge-score": 1.0}}, "mia_loss_acc": 1.0, "mmlu_average": 0.275957840763424, "aggregated-terms": [0.2239950609730358, 0.08333333333333337, 0.1588817413770155, 0.008695652173912993, 0.3958864605377588, 0.02941176470588236, 0.8596933064377682, 0.9259259259259259, 0.862377191025583, 0.992, 0.5559884744058362, 1.0], "aggregate-score": 0.11402526676139003, "harmonic-mean-task-aggregate": 0.06611795952074612, "mia_final_score": 0.0}