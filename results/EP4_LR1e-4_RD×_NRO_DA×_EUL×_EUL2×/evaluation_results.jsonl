{"forget-set": {"overall-regurgitation-score": 0.7310417539046872, "overall-knowledge-score": 0.0, "Task1": {"regurgitation-score": 0.8841269841269841, "knowledge-score": 0.0}, "Task2": {"regurgitation-score": 0.23818389568951787, "knowledge-score": 0.0}, "Task3": {"regurgitation-score": 0.9563854366580334, "knowledge-score": 0.0}}, "retain-set": {"overall-regurgitation-score": 0.7068972653672408, "overall-knowledge-score": 0.0, "Task1": {"regurgitation-score": 0.884515546401942, "knowledge-score": 0.0}, "Task2": {"regurgitation-score": 0.22488952708351795, "knowledge-score": 0.0}, "Task3": {"regurgitation-score": 0.9029648293984875, "knowledge-score": 0.0}}, "mia_loss_acc": 1.0, "mmlu_average": 0.27496083179034325, "aggregated-terms": [0.1158730158730159, 1.0, 0.7618161043104821, 1.0, 0.04361456334196656, 1.0, 0.884515546401942, 0.0, 0.22488952708351795, 0.0, 0.9029648293984875, 0.0], "aggregate-score": 0.09165361059678108, "harmonic-mean-task-aggregate": 0, "mia_final_score": 0.0}