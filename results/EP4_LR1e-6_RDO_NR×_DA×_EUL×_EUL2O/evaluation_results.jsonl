{"forget-set": {"overall-regurgitation-score": 0.9869267449514364, "overall-knowledge-score": 1.0, "Task1": {"regurgitation-score": 1.0, "knowledge-score": 1.0}, "Task2": {"regurgitation-score": 0.9539594061333191, "knowledge-score": 1.0}, "Task3": {"regurgitation-score": 1.0, "knowledge-score": 1.0}}, "retain-set": {"overall-regurgitation-score": 0.9832778343506867, "overall-knowledge-score": 1.0, "Task1": {"regurgitation-score": 1.0, "knowledge-score": 1.0}, "Task2": {"regurgitation-score": 0.9404690902884453, "knowledge-score": 1.0}, "Task3": {"regurgitation-score": 1.0, "knowledge-score": 1.0}}, "mia_loss_acc": 1.0, "mmlu_average": 0.276527560176613, "aggregated-terms": [0.0, 0.0, 0.04604059386668091, 0.0, 0.0, 0.0, 1.0, 1.0, 0.9404690902884453, 1.0, 1.0, 1.0], "aggregate-score": 0.09217585339220434, "harmonic-mean-task-aggregate": 0, "mia_final_score": 0.0}