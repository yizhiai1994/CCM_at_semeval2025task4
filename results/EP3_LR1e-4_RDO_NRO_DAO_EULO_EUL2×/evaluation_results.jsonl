{"forget-set": {"overall-regurgitation-score": 0.5308374273452382, "overall-knowledge-score": 0.30057803468208094, "Task1": {"regurgitation-score": 0.8774281757691895, "knowledge-score": 0.75}, "Task2": {"regurgitation-score": 0.27909685795325295, "knowledge-score": 0.10434782608695652}, "Task3": {"regurgitation-score": 0.45648022539938043, "knowledge-score": 0.6470588235294118}}, "retain-set": {"overall-regurgitation-score": 0.5702337223480254, "overall-knowledge-score": 0.2804232804232804, "Task1": {"regurgitation-score": 0.9055129759726291, "knowledge-score": 0.6296296296296297}, "Task2": {"regurgitation-score": 0.3312252050045323, "knowledge-score": 0.136}, "Task3": {"regurgitation-score": 0.48706272466486417, "knowledge-score": 0.5135135135135135}}, "mia_loss_acc": 0.992, "mmlu_average": 0.27496083179034325, "aggregated-terms": [0.12257182423081048, 0.25, 0.7209031420467471, 0.8956521739130435, 0.5435197746006195, 0.3529411764705882, 0.9055129759726291, 0.6296296296296297, 0.3312252050045323, 0.136, 0.48706272466486417, 0.5135135135135135], "aggregate-score": 0.20687573384748878, "harmonic-mean-task-aggregate": 0.32966636975212305, "mia_final_score": 0.016000000000000014}