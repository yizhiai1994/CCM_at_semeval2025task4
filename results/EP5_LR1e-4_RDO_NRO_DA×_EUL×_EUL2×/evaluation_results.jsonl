{"forget-set": {"overall-regurgitation-score": 0.9264233050393619, "overall-knowledge-score": 0.4797687861271676, "Task1": {"regurgitation-score": 0.9657738095238094, "knowledge-score": 0.625}, "Task2": {"regurgitation-score": 0.7943114406669393, "knowledge-score": 0.4434782608695652}, "Task3": {"regurgitation-score": 0.9880162689493318, "knowledge-score": 0.5}}, "retain-set": {"overall-regurgitation-score": 0.9630807436213666, "overall-knowledge-score": 0.3968253968253968, "Task1": {"regurgitation-score": 0.9797178130511464, "knowledge-score": 0.5555555555555556}, "Task2": {"regurgitation-score": 0.9062616828810378, "knowledge-score": 0.36}, "Task3": {"regurgitation-score": 0.9893314366998578, "knowledge-score": 0.40540540540540543}}, "mia_loss_acc": 1.0, "mmlu_average": 0.27866400797607177, "aggregated-terms": [0.03422619047619058, 0.375, 0.20568855933306074, 0.5565217391304348, 0.01198373105066819, 0.5, 0.9797178130511464, 0.5555555555555556, 0.9062616828810378, 0.36, 0.9893314366998578, 0.40540540540540543], "aggregate-score": 0.1227012639165608, "harmonic-mean-task-aggregate": 0.08943978377361064, "mia_final_score": 0.0}