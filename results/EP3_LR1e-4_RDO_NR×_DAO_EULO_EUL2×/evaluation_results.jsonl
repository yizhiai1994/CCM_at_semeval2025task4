{"forget-set": {"overall-regurgitation-score": 0.5898164757318874, "overall-knowledge-score": 0.8497109826589595, "Task1": {"regurgitation-score": 0.7502011628810165, "knowledge-score": 0.7916666666666666}, "Task2": {"regurgitation-score": 0.6944932944421245, "knowledge-score": 0.8956521739130435}, "Task3": {"regurgitation-score": 0.40579296626381267, "knowledge-score": 0.7352941176470589}}, "retain-set": {"overall-regurgitation-score": 0.5728456136612223, "overall-knowledge-score": 0.7936507936507936, "Task1": {"regurgitation-score": 0.8748395052687461, "knowledge-score": 0.8148148148148148}, "Task2": {"regurgitation-score": 0.6102466851345292, "knowledge-score": 0.856}, "Task3": {"regurgitation-score": 0.327200698519714, "knowledge-score": 0.5675675675675675}}, "mia_loss_acc": 0.932384, "mmlu_average": 0.27496083179034325, "aggregated-terms": [0.24979883711898354, 0.20833333333333337, 0.3055067055578755, 0.10434782608695647, 0.5942070337361873, 0.2647058823529411, 0.8748395052687461, 0.8148148148148148, 0.6102466851345292, 0.856, 0.327200698519714, 0.5675675675675675], "aggregate-score": 0.24450153676880645, "harmonic-mean-task-aggregate": 0.32331177851607606, "mia_final_score": 0.13523200000000002}