{"forget-set": {"overall-regurgitation-score": 0.1769784511343221, "overall-knowledge-score": 0.5202312138728323, "Task1": {"regurgitation-score": 0.1165665199329527, "knowledge-score": 0.4166666666666667}, "Task2": {"regurgitation-score": 0.29242658311936814, "knowledge-score": 0.6260869565217392}, "Task3": {"regurgitation-score": 0.14152490152187513, "knowledge-score": 0.23529411764705882}}, "retain-set": {"overall-regurgitation-score": 0.16080753571801187, "overall-knowledge-score": 0.5343915343915344, "Task1": {"regurgitation-score": 0.1406573741511324, "knowledge-score": 0.2962962962962963}, "Task2": {"regurgitation-score": 0.2649988330424177, "knowledge-score": 0.688}, "Task3": {"regurgitation-score": 0.1051121824530281, "knowledge-score": 0.1891891891891892}}, "mia_loss_acc": 0.99912, "mmlu_average": 0.2792337273892608, "aggregated-terms": [0.8834334800670474, 0.5833333333333333, 0.7075734168806318, 0.3739130434782608, 0.8584750984781249, 0.7647058823529411, 0.1406573741511324, 0.2962962962962963, 0.2649988330424177, 0.688, 0.1051121824530281, 0.1891891891891892], "aggregate-score": 0.1938714917937803, "harmonic-mean-task-aggregate": 0.30062074799208016, "mia_final_score": 0.0017599999999999838}