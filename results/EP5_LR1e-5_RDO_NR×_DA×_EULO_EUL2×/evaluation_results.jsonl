{"forget-set": {"overall-regurgitation-score": 0.8144393963588832, "overall-knowledge-score": 0.9884393063583815, "Task1": {"regurgitation-score": 0.8413460169163116, "knowledge-score": 0.9583333333333334}, "Task2": {"regurgitation-score": 0.8589183329447979, "knowledge-score": 1.0}, "Task3": {"regurgitation-score": 0.765357795333756, "knowledge-score": 0.9705882352941176}}, "retain-set": {"overall-regurgitation-score": 0.8476694788889403, "overall-knowledge-score": 1.0, "Task1": {"regurgitation-score": 0.9097419766793337, "knowledge-score": 1.0}, "Task2": {"regurgitation-score": 0.8652635242030802, "knowledge-score": 1.0}, "Task3": {"regurgitation-score": 0.7904854633972076, "knowledge-score": 1.0}}, "mia_loss_acc": 1.0, "mmlu_average": 0.2802307363623415, "aggregated-terms": [0.1586539830836884, 0.04166666666666663, 0.1410816670552021, 0.0, 0.23464220466624397, 0.02941176470588236, 0.9097419766793337, 1.0, 0.8652635242030802, 1.0, 0.7904854633972076, 1.0], "aggregate-score": 0.09341024545411385, "harmonic-mean-task-aggregate": 0, "mia_final_score": 0.0}