{"forget-set": {"overall-regurgitation-score": 0.8563710729518837, "overall-knowledge-score": 0.9942196531791907, "Task1": {"regurgitation-score": 1.0, "knowledge-score": 1.0}, "Task2": {"regurgitation-score": 0.9298347224434182, "knowledge-score": 0.991304347826087}, "Task3": {"regurgitation-score": 0.7052899497912932, "knowledge-score": 1.0}}, "retain-set": {"overall-regurgitation-score": 0.8454579871625008, "overall-knowledge-score": 1.0, "Task1": {"regurgitation-score": 0.9697581273180178, "knowledge-score": 1.0}, "Task2": {"regurgitation-score": 0.886846053363684, "knowledge-score": 1.0}, "Task3": {"regurgitation-score": 0.7267875698860536, "knowledge-score": 1.0}}, "mia_loss_acc": 0.999968, "mmlu_average": 0.2751032616436405, "aggregated-terms": [0.0, 0.0, 0.07016527755658175, 0.008695652173912993, 0.2947100502087068, 0.0, 0.9697581273180178, 1.0, 0.886846053363684, 1.0, 0.7267875698860536, 1.0], "aggregate-score": 0.0917224205478802, "harmonic-mean-task-aggregate": 0, "mia_final_score": 6.4000000000064e-05}