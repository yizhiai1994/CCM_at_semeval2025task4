{"forget-set": {"overall-regurgitation-score": 0.7289551579611416, "overall-knowledge-score": 0.0, "Task1": {"regurgitation-score": 0.8951260880696364, "knowledge-score": 0.0}, "Task2": {"regurgitation-score": 0.17836007048352762, "knowledge-score": 0.0}, "Task3": {"regurgitation-score": 0.9841194135311782, "knowledge-score": 0.0}}, "retain-set": {"overall-regurgitation-score": 0.7101599100236053, "overall-knowledge-score": 0.005291005291005291, "Task1": {"regurgitation-score": 0.8890100119187996, "knowledge-score": 0.037037037037037035}, "Task2": {"regurgitation-score": 0.18853731473799906, "knowledge-score": 0.0}, "Task3": {"regurgitation-score": 0.9320953730227922, "knowledge-score": 0.0}}, "mia_loss_acc": 0.9947999999999999, "mmlu_average": 0.2756017661301809, "aggregated-terms": [0.10487391193036355, 1.0, 0.8216399295164724, 1.0, 0.015880586468821845, 1.0, 0.8890100119187996, 0.037037037037037035, 0.18853731473799906, 0.0, 0.9320953730227922, 0.0], "aggregate-score": 0.09533392204339369, "harmonic-mean-task-aggregate": 0, "mia_final_score": 0.010400000000000187}