{"forget-set": {"overall-regurgitation-score": 0.5456837992706267, "overall-knowledge-score": 0.9132947976878613, "Task1": {"regurgitation-score": 0.48385697479781126, "knowledge-score": 0.7916666666666666}, "Task2": {"regurgitation-score": 0.7591384199536373, "knowledge-score": 0.9391304347826087}, "Task3": {"regurgitation-score": 0.4449304907894014, "knowledge-score": 0.9117647058823529}}, "retain-set": {"overall-regurgitation-score": 0.526596850775528, "overall-knowledge-score": 0.91005291005291, "Task1": {"regurgitation-score": 0.5474519219451541, "knowledge-score": 0.8148148148148148}, "Task2": {"regurgitation-score": 0.7658975090894035, "knowledge-score": 0.96}, "Task3": {"regurgitation-score": 0.3496886513315612, "knowledge-score": 0.8108108108108109}}, "mia_loss_acc": 1.0, "mmlu_average": 0.2798034468024498, "aggregated-terms": [0.5161430252021888, 0.20833333333333337, 0.2408615800463627, 0.060869565217391286, 0.5550695092105986, 0.08823529411764708, 0.5474519219451541, 0.8148148148148148, 0.7658975090894035, 0.96, 0.3496886513315612, 0.8108108108108109], "aggregate-score": 0.17335278221421183, "harmonic-mean-task-aggregate": 0.24025489984018572, "mia_final_score": 0.0}