{"forget-set": {"overall-regurgitation-score": 0.8634125449436703, "overall-knowledge-score": 0.9942196531791907, "Task1": {"regurgitation-score": 0.9934895833333334, "knowledge-score": 1.0}, "Task2": {"regurgitation-score": 0.8703914282175154, "knowledge-score": 0.991304347826087}, "Task3": {"regurgitation-score": 0.7668724497480718, "knowledge-score": 1.0}}, "retain-set": {"overall-regurgitation-score": 0.799283490068277, "overall-knowledge-score": 0.9841269841269841, "Task1": {"regurgitation-score": 0.9852833508173791, "knowledge-score": 0.9629629629629629}, "Task2": {"regurgitation-score": 0.82239991884006, "knowledge-score": 0.984}, "Task3": {"regurgitation-score": 0.647934653324485, "knowledge-score": 1.0}}, "mia_loss_acc": 1.0, "mmlu_average": 0.2726107392109386, "aggregated-terms": [0.00651041666666663, 0.0, 0.12960857178248464, 0.008695652173912993, 0.23312755025192822, 0.0, 0.9852833508173791, 0.9629629629629629, 0.82239991884006, 0.984, 0.647934653324485, 1.0], "aggregate-score": 0.0908702464036462, "harmonic-mean-task-aggregate": 0, "mia_final_score": 0.0}