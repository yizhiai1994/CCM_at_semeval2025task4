{"forget-set": {"overall-regurgitation-score": 0.44934967914774815, "overall-knowledge-score": 0.023121387283236993, "Task1": {"regurgitation-score": 0.4387755177758826, "knowledge-score": 0.08333333333333333}, "Task2": {"regurgitation-score": 0.20692416307108957, "knowledge-score": 0.0}, "Task3": {"regurgitation-score": 0.6208075245209225, "knowledge-score": 0.058823529411764705}}, "retain-set": {"overall-regurgitation-score": 0.4331718440736151, "overall-knowledge-score": 0.005291005291005291, "Task1": {"regurgitation-score": 0.5000601390287129, "knowledge-score": 0.037037037037037035}, "Task2": {"regurgitation-score": 0.21996374157637394, "knowledge-score": 0.0}, "Task3": {"regurgitation-score": 0.5284209953883012, "knowledge-score": 0.0}}, "mia_loss_acc": 1.0, "mmlu_average": 0.2859279304942316, "aggregated-terms": [0.5612244822241175, 0.9166666666666666, 0.7930758369289104, 1.0, 0.37919247547907753, 0.9411764705882353, 0.5000601390287129, 0.037037037037037035, 0.21996374157637394, 0.0, 0.5284209953883012, 0.0], "aggregate-score": 0.09530931016474387, "harmonic-mean-task-aggregate": 0, "mia_final_score": 0.0}