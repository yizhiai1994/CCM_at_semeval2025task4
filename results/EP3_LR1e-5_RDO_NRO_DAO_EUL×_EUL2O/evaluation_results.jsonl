{"forget-set": {"overall-regurgitation-score": 0.7792231274621819, "overall-knowledge-score": 1.0, "Task1": {"regurgitation-score": 0.7933952933613259, "knowledge-score": 1.0}, "Task2": {"regurgitation-score": 0.9022006335049813, "knowledge-score": 1.0}, "Task3": {"regurgitation-score": 0.6860285797985393, "knowledge-score": 1.0}}, "retain-set": {"overall-regurgitation-score": 0.7057950903081628, "overall-knowledge-score": 1.0, "Task1": {"regurgitation-score": 0.7913264208660328, "knowledge-score": 1.0}, "Task2": {"regurgitation-score": 0.8531453531810643, "knowledge-score": 1.0}, "Task3": {"regurgitation-score": 0.543819347149108, "knowledge-score": 1.0}}, "mia_loss_acc": 1.0, "mmlu_average": 0.2767412049565589, "aggregated-terms": [0.20660470663867414, 0.0, 0.09779936649501875, 0.0, 0.31397142020146074, 0.0, 0.7913264208660328, 1.0, 0.8531453531810643, 1.0, 0.543819347149108, 1.0], "aggregate-score": 0.09224706831885297, "harmonic-mean-task-aggregate": 0, "mia_final_score": 0.0}