{"forget-set": {"overall-regurgitation-score": 0.6556993115784598, "overall-knowledge-score": 0.9421965317919075, "Task1": {"regurgitation-score": 0.8375855045307922, "knowledge-score": 0.9583333333333334}, "Task2": {"regurgitation-score": 0.7761856702999815, "knowledge-score": 0.9391304347826087}, "Task3": {"regurgitation-score": 0.4458035797710783, "knowledge-score": 0.9411764705882353}}, "retain-set": {"overall-regurgitation-score": 0.6084159348041746, "overall-knowledge-score": 0.9153439153439153, "Task1": {"regurgitation-score": 0.8024143942787786, "knowledge-score": 0.8888888888888888}, "Task2": {"regurgitation-score": 0.6656652143590265, "knowledge-score": 0.92}, "Task3": {"regurgitation-score": 0.4281675457586176, "knowledge-score": 0.918918918918919}}, "mia_loss_acc": 0.99992, "mmlu_average": 0.27239709443099275, "aggregated-terms": [0.16241449546920783, 0.04166666666666663, 0.22381432970001847, 0.060869565217391286, 0.5541964202289217, 0.05882352941176472, 0.8024143942787786, 0.8888888888888888, 0.6656652143590265, 0.92, 0.4281675457586176, 0.918918918918919], "aggregate-score": 0.14197561773249434, "harmonic-mean-task-aggregate": 0.15336975876649034, "mia_final_score": 0.00015999999999993797}