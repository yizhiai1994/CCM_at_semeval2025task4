{"forget-set": {"overall-regurgitation-score": 0.46332286561863495, "overall-knowledge-score": 0.9017341040462428, "Task1": {"regurgitation-score": 0.5882990106787748, "knowledge-score": 0.8333333333333334}, "Task2": {"regurgitation-score": 0.40353238893358223, "knowledge-score": 0.9130434782608695}, "Task3": {"regurgitation-score": 0.415550909216072, "knowledge-score": 0.9117647058823529}}, "retain-set": {"overall-regurgitation-score": 0.4661713137981889, "overall-knowledge-score": 0.873015873015873, "Task1": {"regurgitation-score": 0.5193695608071222, "knowledge-score": 0.8888888888888888}, "Task2": {"regurgitation-score": 0.34715304970697913, "knowledge-score": 0.952}, "Task3": {"regurgitation-score": 0.5077687173938383, "knowledge-score": 0.5945945945945946}}, "mia_loss_acc": 1.0, "mmlu_average": 0.27553055120353226, "aggregated-terms": [0.41170098932122523, 0.16666666666666663, 0.5964676110664178, 0.08695652173913049, 0.5844490907839279, 0.08823529411764708, 0.5193695608071222, 0.8888888888888888, 0.34715304970697913, 0.952, 0.5077687173938383, 0.5945945945945946], "aggregate-score": 0.18017795106331877, "harmonic-mean-task-aggregate": 0.2650033019864241, "mia_final_score": 0.0}