{"forget-set": {"overall-regurgitation-score": 0.8456027671426647, "overall-knowledge-score": 0.9942196531791907, "Task1": {"regurgitation-score": 0.921240204224329, "knowledge-score": 0.9583333333333334}, "Task2": {"regurgitation-score": 0.8567842351585263, "knowledge-score": 1.0}, "Task3": {"regurgitation-score": 0.7846477008389955, "knowledge-score": 1.0}}, "retain-set": {"overall-regurgitation-score": 0.807031024351063, "overall-knowledge-score": 1.0, "Task1": {"regurgitation-score": 0.8950791800064832, "knowledge-score": 1.0}, "Task2": {"regurgitation-score": 0.8244223567683645, "knowledge-score": 1.0}, "Task3": {"regurgitation-score": 0.7310287672394715, "knowledge-score": 1.0}}, "mia_loss_acc": 1.0, "mmlu_average": 0.27809428856288276, "aggregated-terms": [0.07875979577567105, 0.04166666666666663, 0.1432157648414737, 0.0, 0.2153522991610045, 0.0, 0.8950791800064832, 1.0, 0.8244223567683645, 1.0, 0.7310287672394715, 1.0], "aggregate-score": 0.09269809618762759, "harmonic-mean-task-aggregate": 0, "mia_final_score": 0.0}