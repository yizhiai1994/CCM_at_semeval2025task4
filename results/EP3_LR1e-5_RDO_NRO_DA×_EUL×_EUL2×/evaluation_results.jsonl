{"forget-set": {"overall-regurgitation-score": 0.9697848676243739, "overall-knowledge-score": 0.7803468208092486, "Task1": {"regurgitation-score": 0.9831349206349206, "knowledge-score": 0.75}, "Task2": {"regurgitation-score": 0.9111885296667905, "knowledge-score": 0.808695652173913}, "Task3": {"regurgitation-score": 1.0, "knowledge-score": 0.7058823529411765}}, "retain-set": {"overall-regurgitation-score": 0.9598213829360797, "overall-knowledge-score": 0.7883597883597884, "Task1": {"regurgitation-score": 0.976976976976977, "knowledge-score": 0.7777777777777778}, "Task2": {"regurgitation-score": 0.8818289881173085, "knowledge-score": 0.84}, "Task3": {"regurgitation-score": 1.0, "knowledge-score": 0.6216216216216216}}, "mia_loss_acc": 1.0, "mmlu_average": 0.2721122347243982, "aggregated-terms": [0.016865079365079416, 0.25, 0.08881147033320946, 0.19130434782608696, 0.0, 0.2941176470588235, 0.976976976976977, 0.7777777777777778, 0.8818289881173085, 0.84, 1.0, 0.6216216216216216], "aggregate-score": 0.09070407824146608, "harmonic-mean-task-aggregate": 0, "mia_final_score": 0.0}