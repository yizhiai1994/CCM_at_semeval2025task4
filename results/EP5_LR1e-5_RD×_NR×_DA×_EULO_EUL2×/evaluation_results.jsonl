{"forget-set": {"overall-regurgitation-score": 0.11678760305110748, "overall-knowledge-score": 0.057803468208092484, "Task1": {"regurgitation-score": 0.08424384248698918, "knowledge-score": 0.0}, "Task2": {"regurgitation-score": 0.15141308149843521, "knowledge-score": 0.0782608695652174}, "Task3": {"regurgitation-score": 0.11633655155846931, "knowledge-score": 0.029411764705882353}}, "retain-set": {"overall-regurgitation-score": 0.10369588921060488, "overall-knowledge-score": 0.06878306878306878, "Task1": {"regurgitation-score": 0.09963907618417868, "knowledge-score": 0.037037037037037035}, "Task2": {"regurgitation-score": 0.12896905156858726, "knowledge-score": 0.096}, "Task3": {"regurgitation-score": 0.08957980523125221, "knowledge-score": 0.0}}, "mia_loss_acc": 0.9296479999999999, "mmlu_average": 0.27332288847742486, "aggregated-terms": [0.9157561575130109, 1.0, 0.8485869185015648, 0.9217391304347826, 0.8836634484415307, 0.9705882352941176, 0.09963907618417868, 0.037037037037037035, 0.12896905156858726, 0.096, 0.08957980523125221, 0.0], "aggregate-score": 0.13800896282580835, "harmonic-mean-task-aggregate": 0, "mia_final_score": 0.14070400000000016}