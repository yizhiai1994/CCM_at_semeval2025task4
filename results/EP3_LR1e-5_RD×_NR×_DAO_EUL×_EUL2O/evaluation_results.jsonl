{"forget-set": {"overall-regurgitation-score": 0.9260559001500211, "overall-knowledge-score": 1.0, "Task1": {"regurgitation-score": 0.9443533255693582, "knowledge-score": 1.0}, "Task2": {"regurgitation-score": 0.8964645821167561, "knowledge-score": 1.0}, "Task3": {"regurgitation-score": 0.9331577267588745, "knowledge-score": 1.0}}, "retain-set": {"overall-regurgitation-score": 0.892348056285341, "overall-knowledge-score": 0.9947089947089947, "Task1": {"regurgitation-score": 0.9617734323818081, "knowledge-score": 1.0}, "Task2": {"regurgitation-score": 0.91472602633655, "knowledge-score": 0.992}, "Task3": {"regurgitation-score": 0.8265660453154797, "knowledge-score": 1.0}}, "mia_loss_acc": 1.0, "mmlu_average": 0.27496083179034325, "aggregated-terms": [0.05564667443064175, 0.0, 0.10353541788324394, 0.0, 0.06684227324112546, 0.0, 0.9617734323818081, 1.0, 0.91472602633655, 0.992, 0.8265660453154797, 1.0], "aggregate-score": 0.09165361059678108, "harmonic-mean-task-aggregate": 0, "mia_final_score": 0.0}