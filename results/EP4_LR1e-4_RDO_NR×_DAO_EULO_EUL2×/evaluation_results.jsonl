{"forget-set": {"overall-regurgitation-score": 0.549963049082519, "overall-knowledge-score": 0.8092485549132948, "Task1": {"regurgitation-score": 0.7408612995375091, "knowledge-score": 0.7916666666666666}, "Task2": {"regurgitation-score": 0.6196236398974159, "knowledge-score": 0.808695652173913}, "Task3": {"regurgitation-score": 0.3680880020336248, "knowledge-score": 0.8235294117647058}}, "retain-set": {"overall-regurgitation-score": 0.4699632923171651, "overall-knowledge-score": 0.7566137566137566, "Task1": {"regurgitation-score": 0.6919333396160013, "knowledge-score": 0.7407407407407407}, "Task2": {"regurgitation-score": 0.4837287669361979, "knowledge-score": 0.816}, "Task3": {"regurgitation-score": 0.2986841533294789, "knowledge-score": 0.5675675675675675}}, "mia_loss_acc": 0.892368, "mmlu_average": 0.27496083179034325, "aggregated-terms": [0.2591387004624909, 0.20833333333333337, 0.38037636010258413, 0.19130434782608696, 0.6319119979663752, 0.17647058823529416, 0.6919333396160013, 0.7407407407407407, 0.4837287669361979, 0.816, 0.2986841533294789, 0.5675675675675675], "aggregate-score": 0.27781734401085006, "harmonic-mean-task-aggregate": 0.3432272002422071, "mia_final_score": 0.2152639999999999}