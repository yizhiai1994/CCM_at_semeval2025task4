{"forget-set": {"overall-regurgitation-score": 0.46627925628785355, "overall-knowledge-score": 0.011560693641618497, "Task1": {"regurgitation-score": 0.6442320751470048, "knowledge-score": 0.041666666666666664}, "Task2": {"regurgitation-score": 0.06427798877940655, "knowledge-score": 0.0}, "Task3": {"regurgitation-score": 0.612607535701814, "knowledge-score": 0.029411764705882353}}, "retain-set": {"overall-regurgitation-score": 0.4814503652498109, "overall-knowledge-score": 0.005291005291005291, "Task1": {"regurgitation-score": 0.6527111309730061, "knowledge-score": 0.037037037037037035}, "Task2": {"regurgitation-score": 0.0678576147557794, "knowledge-score": 0.0}, "Task3": {"regurgitation-score": 0.6359308541099328, "knowledge-score": 0.0}}, "mia_loss_acc": 1.0, "mmlu_average": 0.2867825096140151, "aggregated-terms": [0.35576792485299524, 0.9583333333333334, 0.9357220112205935, 1.0, 0.38739246429818597, 0.9705882352941176, 0.6527111309730061, 0.037037037037037035, 0.0678576147557794, 0.0, 0.6359308541099328, 0.0], "aggregate-score": 0.09559416987133836, "harmonic-mean-task-aggregate": 0, "mia_final_score": 0.0}