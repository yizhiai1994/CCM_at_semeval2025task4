{"forget-set": {"overall-regurgitation-score": 0.5689644031243896, "overall-knowledge-score": 0.930635838150289, "Task1": {"regurgitation-score": 0.7151002094664172, "knowledge-score": 1.0}, "Task2": {"regurgitation-score": 0.7606999003550727, "knowledge-score": 0.9304347826086956}, "Task3": {"regurgitation-score": 0.3361062916974967, "knowledge-score": 0.8823529411764706}}, "retain-set": {"overall-regurgitation-score": 0.5531966444549886, "overall-knowledge-score": 0.9312169312169312, "Task1": {"regurgitation-score": 0.8537649066318878, "knowledge-score": 1.0}, "Task2": {"regurgitation-score": 0.644413149483, "knowledge-score": 0.936}, "Task3": {"regurgitation-score": 0.2722302740637295, "knowledge-score": 0.8648648648648649}}, "mia_loss_acc": 0.806576, "mmlu_average": 0.27496083179034325, "aggregated-terms": [0.28489979053358283, 0.0, 0.23930009964492727, 0.06956521739130439, 0.6638937083025034, 0.11764705882352944, 0.8537649066318878, 1.0, 0.644413149483, 0.936, 0.2722302740637295, 0.8648648648648649], "aggregate-score": 0.22060294393011445, "harmonic-mean-task-aggregate": 0, "mia_final_score": 0.3868480000000001}