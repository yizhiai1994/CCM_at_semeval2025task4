{"forget-set": {"overall-regurgitation-score": 0.9466865592319478, "overall-knowledge-score": 0.5260115606936416, "Task1": {"regurgitation-score": 0.9637896825396824, "knowledge-score": 0.5833333333333334}, "Task2": {"regurgitation-score": 0.8744816730110847, "knowledge-score": 0.5217391304347826}, "Task3": {"regurgitation-score": 0.9834582481641305, "knowledge-score": 0.5}}, "retain-set": {"overall-regurgitation-score": 0.9695568375307712, "overall-knowledge-score": 0.4973544973544973, "Task1": {"regurgitation-score": 0.9548367125359879, "knowledge-score": 0.5555555555555556}, "Task2": {"regurgitation-score": 0.9651505717699267, "knowledge-score": 0.512}, "Task3": {"regurgitation-score": 0.9832757569599675, "knowledge-score": 0.40540540540540543}}, "mia_loss_acc": 1.0, "mmlu_average": 0.27496083179034325, "aggregated-terms": [0.036210317460317554, 0.41666666666666663, 0.1255183269889153, 0.4782608695652174, 0.016541751835869478, 0.5, 0.9548367125359879, 0.5555555555555556, 0.9651505717699267, 0.512, 0.9832757569599675, 0.40540540540540543], "aggregate-score": 0.12741655679011435, "harmonic-mean-task-aggregate": 0.10728883857999978, "mia_final_score": 0.0}