{"forget-set": {"overall-regurgitation-score": 0.04484641597993598, "overall-knowledge-score": 0.0, "Task1": {"regurgitation-score": 0.05415571286166959, "knowledge-score": 0.0}, "Task2": {"regurgitation-score": 0.010070678946241165, "knowledge-score": 0.0}, "Task3": {"regurgitation-score": 0.06179991088032938, "knowledge-score": 0.0}}, "retain-set": {"overall-regurgitation-score": 0.04080065932337191, "overall-knowledge-score": 0.0, "Task1": {"regurgitation-score": 0.06256478096755329, "knowledge-score": 0.0}, "Task2": {"regurgitation-score": 0.010927350427350428, "knowledge-score": 0.0}, "Task3": {"regurgitation-score": 0.04510340089114598, "knowledge-score": 0.0}}, "mia_loss_acc": 0.527488, "mmlu_average": 0.2455490670844609, "aggregated-terms": [0.9458442871383304, 1.0, 0.9899293210537589, 1.0, 0.9382000891196707, 1.0, 0.06256478096755329, 0.0, 0.010927350427350428, 0.0, 0.04510340089114598, 0.0], "aggregate-score": 0.39685768902815366, "harmonic-mean-task-aggregate": 0, "mia_final_score": 0.9450240000000001}