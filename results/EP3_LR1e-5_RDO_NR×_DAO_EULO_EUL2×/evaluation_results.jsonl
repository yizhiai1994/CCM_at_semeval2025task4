{"forget-set": {"overall-regurgitation-score": 0.8081732206639116, "overall-knowledge-score": 0.9884393063583815, "Task1": {"regurgitation-score": 0.925920269423559, "knowledge-score": 1.0}, "Task2": {"regurgitation-score": 0.8505283927023058, "knowledge-score": 0.991304347826087}, "Task3": {"regurgitation-score": 0.6964056286899528, "knowledge-score": 0.9705882352941176}}, "retain-set": {"overall-regurgitation-score": 0.8029364942836311, "overall-knowledge-score": 0.9947089947089947, "Task1": {"regurgitation-score": 0.9467964544964818, "knowledge-score": 1.0}, "Task2": {"regurgitation-score": 0.8303389512538227, "knowledge-score": 1.0}, "Task3": {"regurgitation-score": 0.6794424307700697, "knowledge-score": 0.972972972972973}}, "mia_loss_acc": 1.0, "mmlu_average": 0.27496083179034325, "aggregated-terms": [0.07407973057644102, 0.0, 0.14947160729769415, 0.008695652173912993, 0.3035943713100472, 0.02941176470588236, 0.9467964544964818, 1.0, 0.8303389512538227, 1.0, 0.6794424307700697, 0.972972972972973], "aggregate-score": 0.09165361059678108, "harmonic-mean-task-aggregate": 0, "mia_final_score": 0.0}