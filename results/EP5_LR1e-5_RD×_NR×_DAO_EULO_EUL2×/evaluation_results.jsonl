{"forget-set": {"overall-regurgitation-score": 0.08576197256894125, "overall-knowledge-score": 0.0, "Task1": {"regurgitation-score": 0.05737991921087595, "knowledge-score": 0.0}, "Task2": {"regurgitation-score": 0.1435792389569465, "knowledge-score": 0.0}, "Task3": {"regurgitation-score": 0.06668468297098382, "knowledge-score": 0.0}}, "retain-set": {"overall-regurgitation-score": 0.07269025924860878, "overall-knowledge-score": 0.0, "Task1": {"regurgitation-score": 0.06256478096755329, "knowledge-score": 0.0}, "Task2": {"regurgitation-score": 0.11460597913654932, "knowledge-score": 0.0}, "Task3": {"regurgitation-score": 0.0517576894213111, "knowledge-score": 0.0}}, "mia_loss_acc": 0.715648, "mmlu_average": 0.27496083179034325, "aggregated-terms": [0.9426200807891241, 1.0, 0.8564207610430535, 1.0, 0.9333153170290162, 1.0, 0.06256478096755329, 0.0, 0.11460597913654932, 0.0, 0.0517576894213111, 0.0], "aggregate-score": 0.28122161059678114, "harmonic-mean-task-aggregate": 0, "mia_final_score": 0.5687040000000001}