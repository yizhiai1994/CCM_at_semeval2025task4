{"forget-set": {"overall-regurgitation-score": 0.7539200018828492, "overall-knowledge-score": 0.04046242774566474, "Task1": {"regurgitation-score": 0.957043650793651, "knowledge-score": 0.20833333333333334}, "Task2": {"regurgitation-score": 0.20077293707687752, "knowledge-score": 0.0}, "Task3": {"regurgitation-score": 0.984726322961617, "knowledge-score": 0.058823529411764705}}, "retain-set": {"overall-regurgitation-score": 0.7079914090853415, "overall-knowledge-score": 0.031746031746031744, "Task1": {"regurgitation-score": 0.9530974753555398, "knowledge-score": 0.18518518518518517}, "Task2": {"regurgitation-score": 0.13905767598594657, "knowledge-score": 0.0}, "Task3": {"regurgitation-score": 0.9135449101174907, "knowledge-score": 0.02702702702702703}}, "mia_loss_acc": 0.988032, "mmlu_average": 0.27332288847742486, "aggregated-terms": [0.042956349206349054, 0.7916666666666666, 0.7992270629231225, 1.0, 0.015273677038383005, 0.9411764705882353, 0.9530974753555398, 0.18518518518518517, 0.13905767598594657, 0.0, 0.9135449101174907, 0.02702702702702703], "aggregate-score": 0.0990862961591416, "harmonic-mean-task-aggregate": 0, "mia_final_score": 0.023935999999999957}