{"forget-set": {"overall-regurgitation-score": 0.1992178661467407, "overall-knowledge-score": 0.7225433526011561, "Task1": {"regurgitation-score": 0.1919856219075802, "knowledge-score": 0.5}, "Task2": {"regurgitation-score": 0.2253066348638383, "knowledge-score": 0.8347826086956521}, "Task3": {"regurgitation-score": 0.1866746950069349, "knowledge-score": 0.5}}, "retain-set": {"overall-regurgitation-score": 0.2021672856244015, "overall-knowledge-score": 0.6931216931216931, "Task1": {"regurgitation-score": 0.18187791553116195, "knowledge-score": 0.6666666666666666}, "Task2": {"regurgitation-score": 0.2927746487975438, "knowledge-score": 0.84}, "Task3": {"regurgitation-score": 0.15575185084572346, "knowledge-score": 0.21621621621621623}}, "mia_loss_acc": 1.0, "mmlu_average": 0.27332288847742486, "aggregated-terms": [0.8080143780924198, 0.5, 0.7746933651361617, 0.16521739130434787, 0.8133253049930651, 0.5, 0.18187791553116195, 0.6666666666666666, 0.2927746487975438, 0.84, 0.15575185084572346, 0.21621621621621623], "aggregate-score": 0.2008159294478862, "harmonic-mean-task-aggregate": 0.3291248998662338, "mia_final_score": 0.0}