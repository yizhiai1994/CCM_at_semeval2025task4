{"forget-set": {"overall-regurgitation-score": 0.43766879050347407, "overall-knowledge-score": 0.838150289017341, "Task1": {"regurgitation-score": 0.6174441431712842, "knowledge-score": 0.8333333333333334}, "Task2": {"regurgitation-score": 0.5252205217419302, "knowledge-score": 0.8347826086956521}, "Task3": {"regurgitation-score": 0.25154237042959354, "knowledge-score": 0.8529411764705882}}, "retain-set": {"overall-regurgitation-score": 0.42903071993110137, "overall-knowledge-score": 0.8148148148148148, "Task1": {"regurgitation-score": 0.8224300992653008, "knowledge-score": 0.8518518518518519}, "Task2": {"regurgitation-score": 0.3566579093611255, "knowledge-score": 0.84}, "Task3": {"regurgitation-score": 0.19085604485612864, "knowledge-score": 0.7027027027027027}}, "mia_loss_acc": 0.703648, "mmlu_average": 0.27496083179034325, "aggregated-terms": [0.38255585682871585, 0.16666666666666663, 0.47477947825806976, 0.16521739130434787, 0.7484576295704064, 0.1470588235294118, 0.8224300992653008, 0.8518518518518519, 0.3566579093611255, 0.84, 0.19085604485612864, 0.7027027027027027], "aggregate-score": 0.3946076704546427, "harmonic-mean-task-aggregate": 0.31615817957358483, "mia_final_score": 0.5927039999999999}