{"forget-set": {"overall-regurgitation-score": 0.06987863065202725, "overall-knowledge-score": 0.005780346820809248, "Task1": {"regurgitation-score": 0.06256650756494371, "knowledge-score": 0.0}, "Task2": {"regurgitation-score": 0.08945112744888528, "knowledge-score": 0.0}, "Task3": {"regurgitation-score": 0.06179991088032938, "knowledge-score": 0.029411764705882353}}, "retain-set": {"overall-regurgitation-score": 0.07060139566343283, "overall-knowledge-score": 0.010582010582010581, "Task1": {"regurgitation-score": 0.08814222017534663, "knowledge-score": 0.037037037037037035}, "Task2": {"regurgitation-score": 0.0893943374535506, "knowledge-score": 0.008}, "Task3": {"regurgitation-score": 0.04510340089114598, "knowledge-score": 0.0}}, "mia_loss_acc": 0.8498879999999999, "mmlu_average": 0.27496083179034325, "aggregated-terms": [0.9374334924350562, 1.0, 0.9105488725511147, 1.0, 0.9382000891196707, 0.9705882352941176, 0.08814222017534663, 0.037037037037037035, 0.0893943374535506, 0.008, 0.04510340089114598, 0.0], "aggregate-score": 0.19172827726344785, "harmonic-mean-task-aggregate": 0, "mia_final_score": 0.30022400000000027}