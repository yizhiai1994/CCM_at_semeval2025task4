{"forget-set": {"overall-regurgitation-score": 0.756021487423564, "overall-knowledge-score": 1.0, "Task1": {"regurgitation-score": 0.7631816206368773, "knowledge-score": 1.0}, "Task2": {"regurgitation-score": 0.8776808055068924, "knowledge-score": 1.0}, "Task3": {"regurgitation-score": 0.668668325275444, "knowledge-score": 1.0}}, "retain-set": {"overall-regurgitation-score": 0.6800920719798041, "overall-knowledge-score": 1.0, "Task1": {"regurgitation-score": 0.7893511122240574, "knowledge-score": 1.0}, "Task2": {"regurgitation-score": 0.8149231309588422, "knowledge-score": 1.0}, "Task3": {"regurgitation-score": 0.5092604351941071, "knowledge-score": 1.0}}, "mia_loss_acc": 1.0, "mmlu_average": 0.27496083179034325, "aggregated-terms": [0.23681837936312267, 0.0, 0.12231919449310757, 0.0, 0.33133167472455605, 0.0, 0.7893511122240574, 1.0, 0.8149231309588422, 1.0, 0.5092604351941071, 1.0], "aggregate-score": 0.09165361059678108, "harmonic-mean-task-aggregate": 0, "mia_final_score": 0.0}