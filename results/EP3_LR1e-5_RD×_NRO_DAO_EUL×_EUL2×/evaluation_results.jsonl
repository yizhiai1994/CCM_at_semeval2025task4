{"forget-set": {"overall-regurgitation-score": 0.9058585447474335, "overall-knowledge-score": 0.6242774566473989, "Task1": {"regurgitation-score": 0.898561507936508, "knowledge-score": 0.7916666666666666}, "Task2": {"regurgitation-score": 0.8545747730530338, "knowledge-score": 0.5565217391304348}, "Task3": {"regurgitation-score": 0.9457013574660633, "knowledge-score": 0.7352941176470589}}, "retain-set": {"overall-regurgitation-score": 0.895993384513577, "overall-knowledge-score": 0.5661375661375662, "Task1": {"regurgitation-score": 0.9013802691580471, "knowledge-score": 0.7407407407407407}, "Task2": {"regurgitation-score": 0.7872004649237081, "knowledge-score": 0.52}, "Task3": {"regurgitation-score": 0.9655711440904974, "knowledge-score": 0.5945945945945946}}, "mia_loss_acc": 1.0, "mmlu_average": 0.269690927218345, "aggregated-terms": [0.10143849206349198, 0.20833333333333337, 0.14542522694696625, 0.4434782608695652, 0.05429864253393668, 0.2647058823529411, 0.9013802691580471, 0.7407407407407407, 0.7872004649237081, 0.52, 0.9655711440904974, 0.5945945945945946], "aggregate-score": 0.16348833294671977, "harmonic-mean-task-aggregate": 0.22077407162181437, "mia_final_score": 0.0}